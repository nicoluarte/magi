* Diplomado data science
#+STARTUP: latexpreview
** 09/07/2019, Cross validations, decision trees
*** Cross-validation
- Allows us to compare different machine learning methods and get a
  sense of how well they will work in practice
- Typically this method split the data base into 75%~ for training and
  25%~ for testing
- A similar principle is followed by 'leave one out cross validation',
  where the model is trained in all but one sample, and that sample is
  used to test model accuracy
- k-fold validation is the generalization, where data is divided in k
  blocks
#+BEGIN_SRC R :results output 
                                        # Load pkg
pkg <- c("tidyverse", "caret")
lapply(pkg, library, character.only = TRUE)

                                        # load sample data
data("swiss")

                                        # data-split
set.seed(123)
training.samples <- swiss$Fertility %>%
  createDataPartition(p = 0.8, list = FALSE) # 80/20 split
train.data <- swiss[training.samples, ]
test.data <- swiss[-training.samples, ]

                                        # build the model
model <- lm(Fertility ~ ., data = train.data)

                                        # make predictions and compute acc
predictions <- model %>% predict(test.data)
data.frame(R2 = R2(predictions, test.data$Fertility),
           RMSE = RMSE(predictions, test.data$Fertility),
           MAE = MAE(predictions, test.data$Fertility))

                                        # repeated k-fold cross validation

                         number = 5, repeats = 10)
model.2 <- train(Fertility ~ .,
                 data = swiss,
                 method = "lm",
                 trControl = t.control)
predictions_2 <- model %>% predict(swiss)
data.frame(R2 = R2(predictions_2, swiss$Fertility),
           RMSE = RMSE(predictions_2, swiss$Fertility),
           MAE = MAE(predictions_2, swiss$Fertility))
#+END_SRC
*** Confusion matrix
- The confusion matrix can be used to compute various summaries for
  classification models
- Rows correspond to what it was predicted
- Columns correspond to the known truth
- Sensitivity:
\begin{equation}
\frac{T.positives}{T.positives + F.negatives}
\end{equation}
 
- Specificity:
\begin{equation}
\frac{T.negatives}{T.negatives + F.positives}
\end{equation}

#+BEGIN_SRC R :results output
                                        # Load pkg
pkg <- c("tidyverse", "caret")
lapply(pkg, library, character.only = TRUE)

                                        # Using dummy data
x <- factor(ceiling(runif(1000)-0.20)) # predictions
y <- factor(ceiling(runif(1000)-0.25)) # references
table(x, y)

                                        # confusion matrix
confusionMatrix(x, y, positive = "1")
#+END_SRC
*** Decision tree
R code to generate a decision tree
- First a tree is generated
- Later on is pruned
- In this example the difference is not very notorious
#+BEGIN_SRC R :results output :session rs
library(rpart)
library(tree)
setwd("/home/nicoluarte/Downloads")
df = read.table('cleveland.txt', h=T)
head(df)
summary(df)

                                        # Using rpart

## no data standarization needed for trees

set.seed(123)

## creating the first tree

tree.1 = rpart(df[,14] ~ .,
               data=df[,1:13],
               cp=0.0001,parms=list(split="information"),
               method="class")

##split information means entropy/ split could be gini - cp is the complexity parameter.

par(xpd=TRUE)
plot(tree.1, uniform=T);
text(tree.1, all=T, pretty=T, fancy=T, use.n=T, fwidth=0.3, fheight=0.3)

##pretty is for compatibility with tree package. Considers the minimum length for abbreviation of character or factor variables (4 L).

## Pruning

plotcp(tree.1) ## Cross-validation results

printcp(tree.1)

tree.1$cptable[which.min(tree.1$cptable[,"xerror"]),"CP"]

tree.2<-prune(tree.1,cp=0.01102941)

par(xpd=TRUE)
plot(tree.2, uniform=T);
text(tree.2, all=T, pretty=T, fancy=T, use.n=T, fwidth=0.3, fheight=0.3)

plotcp(tree.2) ## Cross-validation results

printcp(tree.2)

#+END_SRC

#+RESULTS:
#+begin_example
  age gender     cp trestbps chol  fbs restecg thatach exang oldpeak slope ca
1  63   male angina      145  233 true     hyp     150   fal     2.3  down  0
2  67   male asympt      160  286  fal     hyp     108  true     1.5  flat  3
3  67   male asympt      120  229  fal     hyp     129  true     2.6  flat  2
4  37   male notang      130  250  fal    norm     187   fal     3.5  down  0
5  41    fem abnang      130  204  fal     hyp     172   fal     1.4    up  0
6  56   male abnang      120  236  fal    norm     178   fal     0.8    up  0
  thal diag Col15
1  fix buff     H
2 norm sick    S2
3  rev sick    S1
4 norm buff     H
5 norm buff     H
6 norm buff     H
      age         gender         cp         trestbps          chol      
 Min.   :29.00   fem : 95   abnang: 49   Min.   : 94.0   Min.   :126.0  
 1st Qu.:48.00   male:201   angina: 23   1st Qu.:120.0   1st Qu.:211.0  
 Median :56.00              asympt:141   Median :130.0   Median :242.5  
 Mean   :54.52              notang: 83   Mean   :131.6   Mean   :247.2  
 3rd Qu.:61.00                           3rd Qu.:140.0   3rd Qu.:275.2  
 Max.   :77.00                           Max.   :200.0   Max.   :564.0  
   fbs      restecg       thatach       exang        oldpeak       slope    
 fal :253   abn :  4   Min.   : 71.0   fal :199   Min.   :0.000   down: 21  
 true: 43   hyp :145   1st Qu.:133.0   true: 97   1st Qu.:0.000   flat:137  
            norm:147   Median :152.5              Median :0.800   up  :138  
                       Mean   :149.6              Mean   :1.059             
                       3rd Qu.:166.0              3rd Qu.:1.650             
                       Max.   :202.0              Max.   :6.200             
       ca           thal       diag     Col15   
 Min.   :0.0000   fix : 18   buff:160   H :160  
 1st Qu.:0.0000   norm:163   sick:136   S1: 53  
 Median :0.0000   rev :115              S2: 35  
 Mean   :0.6791                         S3: 35  
 3rd Qu.:1.0000                         S4: 13  
 Max.   :3.0000

Classification tree:
rpart(formula = df[, 14] ~ ., data = df[, 1:13], method = "class", 
    parms = list(split = "information"), cp = 1e-04)

Variables actually used in tree construction:
[1] age     ca      cp      exang   oldpeak thal    thatach

Root node error: 136/296 = 0.45946

n= 296 

         CP nsplit rel error  xerror     xstd
1 0.4926471      0   1.00000 1.00000 0.063044
2 0.0514706      1   0.50735 0.63971 0.057630
3 0.0404412      3   0.40441 0.52941 0.054276
4 0.0220588      5   0.32353 0.44853 0.051170
5 0.0110294      6   0.30147 0.44118 0.050857
6 0.0036765      8   0.27941 0.44118 0.050857
7 0.0001000     10   0.27206 0.46324 0.051780
[1] 0.01102941

Classification tree:
rpart(formula = df[, 14] ~ ., data = df[, 1:13], method = "class", 
    parms = list(split = "information"), cp = 1e-04)

Variables actually used in tree construction:
[1] age   ca    cp    exang thal 

Root node error: 136/296 = 0.45946

n= 296 

        CP nsplit rel error  xerror     xstd
1 0.492647      0   1.00000 1.00000 0.063044
2 0.051471      1   0.50735 0.63971 0.057630
3 0.040441      3   0.40441 0.52941 0.054276
4 0.022059      5   0.32353 0.44853 0.051170
5 0.011029      6   0.30147 0.44118 0.050857
6 0.011029      8   0.27941 0.44118 0.050857
#+end_example
** 11/07/2019, GLM
*** Linear regression
**** Conditions
**** Multiple linear regression
*** GLM
- A function is applied to the X's, or a transformation. These are
called link functions
- Started modelling probability of event (Bernoulli, logit of 'p')
- Logit predicts 'odds' <- logistic regression
- In GLM response variable can have any distribution
Using coimbra breast cancer dataset
*CHALLENGE REMOVE OUTLIERS AND RE-RUN ANALYSIS*
- There's not much difference in removing outliers
#+BEGIN_SRC R :results output
setwd("/home/nicoluarte/Downloads/")
df <- read.csv("dataR2.csv")
head(df)
resp <- c(df$Classification - 1)

                                        # compare cancer/no-cancer by age
library(doBy)
summaryBy(Age~resp, data = df, FUN = c(mean, median))

                                        # compare by glucose
summaryBy(Glucose~resp, data = df, FUN = c(mean, median))
summaryBy(Insulin~resp, data = df, FUN = c(mean, median))

                                        # t-test to check means
t.test(Age~resp, data = df)
t.test(Glucose~resp, data = df)
t.test(BMI~resp, data = df)
                                        # re-code variable
df$Glucose2 <- ifelse(df$Glucose<=100, "<=100", ">100")
chisq.test(table(df$Glucose2, resp))

                                        # OR calculation
or <- (44*27)/(8*37)

                                        # Plots
plot(resp~Glucose, data = df)
abline(lm(resp~Glucose, data = df), col = "red")

                                        # Logistic regression
mdl.0 = glm(resp~Glucose2, data = df, family = binomial(link = "logit"))
mdl.1 = glm(resp~Glucose, data = df, family = binomial(link = "logit"))

                                        # Calculating odds
exp(1.3897) # 4 times greater the chance to get cancer

                                        # Box plot
boxplot(Glucose~resp, data = df)

                                        # Logistic regression insulin2
df$Insulin2 <- ifelse(df$Insulin<=8, "<=8", ">8")
mdl.2 = glm(resp~Insulin2, data = df, family = binomial(link = "logit"))
summary(mdl.2)

mdl.3 <- glm(resp~Glucose, data = df, family = binomial(link = "logit"))
summary(mdl.3)

                                        # Calculating odds for different values
exp(0.07867*5)
plot(0.07867*1:10)

                                        # multi-variable model
mdl.4 <- glm(resp~Glucose + Insulin, data = df, family = binomial(link = "logit"))
summary(mdl.4)
plot(Glucose~Insulin, data = df)

                                        # Adding control variables
mdl.5 <- glm(resp~Age + BMI + Glucose, data = df, family = binomial(link = "logit"))
summary(mdl.5)
exp(mdl.5$coefficients["Glucose"]) # each glucose point has a 10%~ effect on chance of cancer

                                        # ROC curve
library(pROC)
prob <- predict(mdl.5, type = c("response"))
roc(resp~prob, data = df, plot = T)

                                        # Use all variables
full.mdl <- glm(resp~., data = df[,1:9], family = binomial(link = "logit"))
summary(full.mdl)

                                        # Prune!

new_vars = setdiff(names(df[,1:9]),c(names(full.mdl$coefficients)[which.max(full.mdl$coefficients)]))
prune.mdl <- glm(resp~., data = df[new_vars], family = binomial(link = "logit"))
summary(prune.mdl)

                                        # Calculate confusion matrix
library(caret)
preds <- as.numeric(predict(full.mdl, type = c("response")) > 0.5)
confusionMatrix(as.factor(preds), as.factor(resp))

                                        # Generate same model without outliers
df_removed_outliers = df[NA,] # same df but NA rows
df_removed_outliers["Classification"] <- df["Classification"]
df_removed_outliers$Classification <- df_removed_outliers$Classification - 1 # to get same levels
for (var in names(df[,1:9]))
{
  outliers <- boxplot.stats(df[,var]) # get the outlier of this variable
  df_target <- df[,var] # get the vector of values of this variable
  idx <- which(df_target %in% outliers$out) # get the idx of outliers in vector
  df_target[idx] <- NA # put NAN's in there
  df_removed_outliers[var] <- df_target # replace with filtered values
}

clean_df = na.omit(df_removed_outliers[,1:10])
full.mdl.filtered <- glm(resp~., data = clean_df[,1:9], # cleaning na rows
                         family = binomial(link = "logit"))
summary(full.mdl.filtered)

preds_filtered <- as.numeric(predict(full.mdl.filtered, type = c("response")) > 0.5)
confusionMatrix(as.factor(preds_filtered), as.factor(clean_df$Classification))
#+END_SRC

* PhD
** Doctorado en neurociencias UC
*** TODO postulacion
    DEADLINE: <2019-09-30 Mon> SCHEDULED: <2019-09-02 Mon>
    
*** Documentos
**** TODO Formulario de postulacion (segun formato en linea)
    SCHEDULED: <2019-08-19 Mon>
**** TODO Certificado de titulo o grado academico, original o copia legalizada ante notario
     SCHEDULED: <2019-08-05 Mon>
**** TODO Concentracion de notas de pregrado y otros estudios
     SCHEDULED: <2019-08-05 Mon>
Incluyendo estudios de perfeccionamiento y postgrado
**** TODO Dos cartas de recomendacion confidenciales (segun formato en linea)
     SCHEDULED: <2019-08-05 Mon>
Estas debe ser enviadas directamente por las personas que
recomiendan. Es deseable que las cartas provengan de personas con
grado academico de Doctor
**** TODO Carta de intencion
     SCHEDULED: <2019-07-10 Wed>
Presentar una declaracion de propositos, que incluya la formulacion de
un topico de interes relevante para su estudio durante el programa y
la dedicacion comprometidos para el programa. El postulante debe ser
tan especifico como sea posible en cuanto a sus intereses y objetivos
de investigacion a corto y largo plazo, en una extension no mas de
tres paginas a espacio y medio.
***** Declaraci√≥n de prop√≥sitos
****** Motivaci√≥n I
El c√≥mo buscamos objetos, informaci√≥n, recompensas, alimentos, etc. Ha
sido lo que ha inspirado en mayor medida mi inter√©s en la
neurociencia. A lo largo de mi vida he sentido profunda intriga en
c√≥mo los humanos buscan en el espacio de posibilidades, para tomar una
decisi√≥n, para evocar una memoria en part√≠cular o bien simplemente
para organizar cualquier compartamiento relativamente complejo, esto
es, sin tener de antemano consideradas todas las posibilidades y a√∫n
pese a eso tener un buen desempe√±o en multiples tareas. Investigar
sobre los mecanismo subyacentes a ese fen√≥meno ha sido incre√≠blemente
enriquecedor debido a la fuerte interdisciplinareidad que subyace al
campo. Esto me ha llevado a generar un profunda inter√©s en seguir
desarrollando carrera en neurociencia, ya que, creo, el lograr
entender ese aparentemente simple mecainsmo de decisi√≥n en condiciones
de informaci√≥n incompleta, puede eventualmente, ser de gran utilidad
para la comprensi√≥n tanto de procesos de memoria y aprendizaje c√≥mo de
ciertas patolog√≠as. Con la oportunidad del programa de Doctorado
espero contribuir a la investigaci√≥n del aprendizaje y memoria.
****** Background
C√≥mo parte de mi formaci√≥n en el programa de Mag√≠ster en Neurociencias
Social de la Universidad Diego Portales, investigue, c√≥mo parte de un
art√≠culo de revisi√≥n, las ra√≠ces evolutivas de la b√∫squeda sem√°ntica
(recuperaci√≥n de memorias en tareas de evocaci√≥n). Una de las
principales conclusiones fue que, aunque solo en grado tentativo,
parace existir un mecanismo compartido entre la b√∫squeda sem√°ntica y
el forrajeo ('foraging', el comportamiento de b√∫squeda de alimento),
teniendo este √∫ltimo patrones relativamente marcados que se extienden
a lo largo de miles de a√±os, as√≠ c√≥mo a trav√©s de multiples
especies. La posibilidad de que un mecanismo tan ubiquo, responsable
del comportamiento motil en la b√∫squeda de alimentos, pueda estar
relacionado por exaptaci√≥n a un proceso fundamental de la memoria. Lo
que abre una posibilidad de establecer un mapeo evolutivo al menos a
este proceso de memoria.
****** Motivaci√≥n II
Deseoso de aprender m√°s sobre este posible v√≠nculo entre forrajeo y
memoria, me adentre en las principales √°reas aleda√±as de conocimiento,
tales como ecolog√≠a, aprendizaje por reforzamiento ('reinforcement
learning') y modelos computacionales. Por la alta carga de modelos
estad√≠sticos de las √°reas mencionadas, me apunt√© para un programa de
diplomado en ciencia de datos de la Universidad Cat√≥lica de
Chile. Adem√°s de este programa he realizado aprendizaje autonomo en
cursos en l√≠nea, con el fin de contar con todas las herramientas
t√©cnicas que son demandadas para el √°rea.
****** Motivaci√≥n III (investigaci√≥n) 
Adicional los programas mencionados anteriormente, desde julio del a√±o
2018, me encuentro participando como investigador en un proyecto
FONDECYT conjunto entre la escuela de Arquitectura y Psicolog√≠a de la
Univerdad Diego Portales. El tema central de esta investigaci√≥n es el
estudio de la percepci√≥n de peatones en diferentes √°mbientes
urbanos. Si bien, el tema no est√° relacionado directamente con el √°rea
de inter√©s, mi rol ha consistido en utilizaci√≥n de t√©cnicas de visi√≥n
de m√°quina ('machine vision') y procesamiento de datos tanto para
'Eye-tracker' c√≥mo para an√°lisis de frecuencia de objetos. Lo
anterior, adicionado, a el aprendizaje de diversos lenguajes de
programaci√≥n (MATLAB, Python, R, Bash) me ha permitido desarrollar
herramientas que son √∫tiles en la investigaci√≥n en general c√≥mo
especificamente para el √°rea de mi inter√©s.
****** Formulaci√≥n t√≥pico de inter√©s
******* Introducci√≥n
Mi t√≥pico de inter√©s reside en el estudio de la memoria,
especificamente la b√∫squeda sem√°ntica. Las memorias sem√°nticas han
sido pensadas, teoricamente, c√≥mo elementos pertenecientes a cierto
'espacio' que correlaciona con la similitud en significado (Lund
1996). As√≠ se ha propuesto una 'distancia' entre los distintos
contenidos sem√°nticos (Montez 2015), considerando aquello es esperable
que a lo largo de la evoluci√≥n se hayan generado estrategias para
acceder, de manera √∫til e eficiente, a dichos contenidos. Las
estrategias de b√∫squeda para acceder a los contenidos sem√°nticos han
sido relacionadas a aquellas del forrajeo (Hills 2015, 2008, 2006,
2009, Abbott 2015). M√°s a√∫n, se ha propuesto que dichos contenidos se
agrupan en 'parches' (Abbot 2015), y que la b√∫squeda a trav√©s de ellos
puede ser descrita por caminatas aleatorias (Hills 2015), a la vez que
siguen comportamiento basados en reglas similares a los del forrajeo
(Davelaar 2015).

Dado que la b√∫squeda sem√°ntica es un comportamiento orientado a
objetivos, se puede conceptualizar c√≥mo un comportamiento orientado a
la obtenci√≥n de recompensas en un espacio de m√∫tliples
posibilidades. Por lo anterior, puede ser estudiado desde el dilema de
exploraci√≥n-explotaci√≥n, dilema extensamente estudiado en la tarea
'n-armed bandit' (Macready 1998, Vermorel 2005). Ha sido propuesto que
los 'algoritmos' utilizados en el forrajeo, pueden proveer de
soluciones √≥ptimas para dicho dilema (Viswanathan, Bartumeus 2005), lo
cu√°l aplicaria, igualmente, para estrategias en espacios sem√°nticos
(Abbot 2015, Montez 2015). De esta manera se puede observar una
conexi√≥n entre un mecanismo evolutivamente antiguo (forrajeo) y el
proceso de acceso en la memoria. Lo c√∫al permitiria un enfoque
evolutivo comprensivo al estudio de la memoria.
******* Relevancia
El c√≥mo se realiza la b√∫squeda en espacios sem√°nticos es de
fundamental importacia, ya que es un espacio que est√° en activa
b√∫squeda durante la comprensi√≥n y producci√≥n de lenguaje, entre otras
(https://doi.org/10.1111/cogs.12249), por lo mismo el alcance de su
importancia para casi cualquier actividad cognitiva es de gran tama√±o,
puediendo afectar de manera importante el comportamiento ante m√∫ltiples y
diferentes tareas.
****** Objetivos a corto plazo
Uno de los principales t√≥picos de discusi√≥n en el √°rea de b√∫squeda
sem√°ntica es la organizaci√≥n y el tipo de la relaciones que conforman
el espacio sem√°ntico (Lund & Burgess 1996). Uno de los primeros
objetivos de investigaci√≥n ser√≠a poder generar configuraciones
experimentales que permitiesen determinar, principalmente, (a) efecto
del contexto en las relaciones entre contenidos sem√°nticos y (b) si el
tipo de b√∫squeda es m√°s verosimil para contenidos encadenados de
manera asociativa o categorica.

Secundariamente, de manera experimental, ajustar modelos en tareas de
evocaci√≥n de memoria, a modo de sugerir posibles mecanismos
generadores del comportamiento de b√∫squeda sem√°ntica. Los modelos mas
relevantes son (a) aquellos basados en reglas (Charnov 1976), (b)
modelos aleatorios simples (10.3389/fpsyg.2014.00086) y (c) modelos aleatorios
complejos (buscar cita, compound brownian walks) 

La metodolog√≠a propuesta para el primer paso comprende,
principalmente, revisi√≥n de la literatura y estudios experimentales de
replica para el segundo paso. Las tareas especificas estar√≠an
orientadas a evocaci√≥n de memoria simple basada en categor√≠a dentro de
franjas de tiempo.
****** Objetivos a largo plazo
******* Hip√≥tesis sobre mecanismos subyacentes
******* Vinculaci√≥n con mecanismos de b√∫squeda en espacios naturales

****** Compromiso
******* Disposici√≥n de investigaci√≥n, demostrar comportamiento pasado
******* Disposici√≥n a aprendizaje autonomo detallando t√©cnicas a aprender
**** TODO Fotocopia de la cedula de identidad o pasaporte
     SCHEDULED: <2019-07-10 Wed>
**** TODO Solicitud de ingreso a la universidad (segun formato)
     SCHEDULED: <2019-07-10 Wed>
** Doctorado en ingenieria de sistemas complejos
*** TODO postulacion
    SCHEDULED: <2019-09-01 Sun> DEADLINE: <2019-11-20 Wed>
*** Documentos
*SEND ALL BACKGROUND INFORMATION TO ANDREA PINTO AT EMAIL: postgrados.fic@uai.cl*
**** TODO Enter information at website [[https://ingenieria.uai.cl/phd/disc/admission/][application]]
     SCHEDULED: <2019-08-05 Mon>
**** TODO R√©sum√©
     SCHEDULED: <2019-07-12 Fri>
**** TODO Photocopy of chilean ID
     SCHEDULED: <2019-07-10 Wed>
**** TODO Statement of interest
Format is open, to be determined by the applicant
**** TODO Letters of recommendation
     SCHEDULED: <2019-08-05 Mon>
At least two letters of recomendation from academic or direct
supervisors
**** TODO Certificates of degrees earned
     SCHEDULED: <2019-08-05 Mon>
**** TODO Grade point average
     SCHEDULED: <2019-08-05 Mon>
With ranking or relative position within the undergraduate and
graduate programs you have completed with their respective grade
scales
**** TODO English proficiency (TOEFL)
     SCHEDULED: <2019-08-05 Mon>
**** TODO Academic interview with the program director
** Doctorado en ciencias de la complejidad social (TBD)
[[https://dccs.udd.cl/es/][PHD PROGRAM]]
** Becas
   SCHEDULED: <2019-07-12 Fri>
*REVISAR*

* Projects
** FONDECYT
*** Initial inspection:
 #+BEGIN_SRC R :results output :session peatones
                                        # load packages
pkg <- c("dplyr", "ggplot2", "tidyverse", "corrplot", "Hmisc", "psycho")
lapply(pkg, library, character.only = TRUE)

                                        # load database
setwd("/home/nicoluarte/Downloads")
df <- data.frame(read.csv("data_fondecyt.csv"))
head(df)

                                        # inspect de data
cor <- na.omit(df) %>%
  correlation()
summary(cor)

                                        # logistic regression model
mdl.0 <- glm(Valence_num~Noise, data = df, family = binomial(link = "logit"))
summary(mdl.0)
t <- 0.5
mdl.0.pred <- as.numeric(predict(mdl.0, type = c("response")) > t)
caret::confusionMatrix(as.factor(mdl.0.pred), as.factor(df$Valence_num), positive = "1")

                                        # cross-validation
t.samples <- df$Valence_num %>%
  caret::createDataPartition(p = 0.8, list = FALSE)
t.data <- df[t.samples, ]
val.data <- df[-t.samples, ]

## re-build model with training data
mdl.1 <- glm(Valence_num~Noise, data = t.data, family = binomial(link = "logit"))
mdl.1.pred <- mdl.1 %>% predict(val.data, type = "response")

## ROC curve
pROC::roc(Valence_num~mdl.1.pred, data = val.data, plot = T)

caret::confusionMatrix(as.factor(as.numeric(mdl.1.pred > t)),
                       as.factor(val.data$Valence_num), positive = "1")

                                        # Repeated k-fold cross-validation
## fix pupil
df$Pupil <- as.numeric(as.character(df$Pupil))
t.control <- caret::trainControl(method = "repeatedcv",
                                 number = 5, repeats = 10)
mdl.2 <- caret::train(as.factor(Valence_num)~Noise+Pedestrians+Cars+Pupil+Neighbourhood_num+Socioeconomic_num,
                      data = na.omit(df),
                      method = "glm",
                      family = binomial(link = "logit"),
                      trControl = t.control,
                      preProcess=c("center", "scale"))
print(mdl.2)
 #+END_SRC

 #+RESULTS:
 #+begin_example

 Attaching package: ‚Äòdplyr‚Äô

 The following objects are masked from ‚Äòpackage:stats‚Äô:

     filter, lag

 The following objects are masked from ‚Äòpackage:base‚Äô:

     intersect, setdiff, setequal, union

 ‚îÄ‚îÄ [1mAttaching packages[22m ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.2.1 ‚îÄ‚îÄ
 [32m‚úî[39m [34mtibble [39m 2.1.3     [32m‚úî[39m [34mpurrr  [39m 0.3.2
 [32m‚úî[39m [34mtidyr  [39m 0.8.3     [32m‚úî[39m [34mstringr[39m 1.4.0
 [32m‚úî[39m [34mreadr  [39m 1.3.1     [32m‚úî[39m [34mforcats[39m 0.4.0
 ‚îÄ‚îÄ [1mConflicts[22m ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ
 [31m‚úñ[39m [34mdplyr[39m::[32mfilter()[39m masks [34mstats[39m::filter()
 [31m‚úñ[39m [34mdplyr[39m::[32mlag()[39m    masks [34mstats[39m::lag()
 corrplot 0.84 loaded
 [[1]]
 [1] "dplyr"      "tikzDevice" "stats"      "graphics"   "grDevices" 
 [6] "utils"      "datasets"   "methods"    "base"      

 [[2]]
  [1] "ggplot2"    "dplyr"      "tikzDevice" "stats"      "graphics"  
  [6] "grDevices"  "utils"      "datasets"   "methods"    "base"      

 [[3]]
  [1] "forcats"    "stringr"    "purrr"      "readr"      "tidyr"     
  [6] "tibble"     "tidyverse"  "ggplot2"    "dplyr"      "tikzDevice"
 [11] "stats"      "graphics"   "grDevices"  "utils"      "datasets"  
 [16] "methods"    "base"      

 [[4]]
  [1] "corrplot"   "forcats"    "stringr"    "purrr"      "readr"     
  [6] "tidyr"      "tibble"     "tidyverse"  "ggplot2"    "dplyr"     
 [11] "tikzDevice" "stats"      "graphics"   "grDevices"  "utils"     
 [16] "datasets"   "methods"    "base"

   Subjects Valence_num  Valence       Noise Pedestrians      Cars       Pupil
 1        1           0 Negative 0.010767789  0.00000000 0.0000000         2.3
 2        1           0 Negative 0.012513303  0.46391753 0.1546392          []
 3        1           1 Positive 0.010372872  0.41237113 0.0000000  2.52325703
 4        1           1 Positive 0.009794006  0.09278351 0.0000000 2.079852955
 5        1           1 Positive 0.013058803  0.48453608 0.0000000 2.505264791
 6        1           1 Positive 0.024941132  0.16494845 0.0000000 2.590279936
   Neighbourhood_num Neighbourhood Socioeconomic_num Socioeconomic Sex_num
 1                 1          Cumm                 1        Middle       0
 2                 1          Cumm                 1        Middle       0
 3                 1          Cumm                 1        Middle       0
 4                 1          Cumm                 1        Middle       0
 5                 1          Cumm                 1        Middle       0
 6                 1          Cumm                 1        Middle       0

		       Subjects Valence_num      Noise  Pedestrians        Cars
 Subjects           1.000000000 -0.19441834  0.3631354  0.004621815  0.18556553
 Valence_num       -0.194418342  1.00000000 -0.1749219 -0.089847534 -0.04749806
 Noise              0.363135383 -0.17492187  1.0000000  0.133186803  0.10435992
 Pedestrians        0.004621815 -0.08984753  0.1331868  1.000000000 -0.06622748
 Cars               0.185565531 -0.04749806  0.1043599 -0.066227485  1.00000000
 Neighbourhood_num  0.986545524 -0.21435181  0.3646531 -0.009562540  0.18292625
 Socioeconomic_num  0.946027834 -0.18731924  0.3565664  0.011485792  0.12835608
 Sex_num            0.034478219  0.01316946  0.1426443  0.095992050  0.13677510
		   Neighbourhood_num Socioeconomic_num     Sex_num
 Subjects                 0.98654552        0.94602783  0.03447822
 Valence_num             -0.21435181       -0.18731924  0.01316946
 Noise                    0.36465314        0.35656638  0.14264431
 Pedestrians             -0.00956254        0.01148579  0.09599205
 Cars                     0.18292625        0.12835608  0.13677510
 Neighbourhood_num        1.00000000        0.95990857 -0.02666244
 Socioeconomic_num        0.95990857        1.00000000 -0.05920530
 Sex_num                 -0.02666244       -0.05920530  1.00000000
 #+end_example



 
