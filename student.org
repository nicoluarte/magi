* Diplomado data science
#+STARTUP: latexpreview
** 09/07/2019, Cross validations, decision trees
*** Cross-validation
- Allows us to compare different machine learning methods and get a
  sense of how well they will work in practice
- Typically this method split the data base into 75%~ for training and
  25%~ for testing
- A similar principle is followed by 'leave one out cross validation',
  where the model is trained in all but one sample, and that sample is
  used to test model accuracy
- k-fold validation is the generalization, where data is divided in k
  blocks
#+BEGIN_SRC R :results output 
                                        # Load pkg
pkg <- c("tidyverse", "caret")
lapply(pkg, library, character.only = TRUE)

                                        # load sample data
data("swiss")

                                        # data-split
set.seed(123)
training.samples <- swiss$Fertility %>%
  createDataPartition(p = 0.8, list = FALSE) # 80/20 split
train.data <- swiss[training.samples, ]
test.data <- swiss[-training.samples, ]

                                        # build the model
model <- lm(Fertility ~ ., data = train.data)

                                        # make predictions and compute acc
predictions <- model %>% predict(test.data)
data.frame(R2 = R2(predictions, test.data$Fertility),
           RMSE = RMSE(predictions, test.data$Fertility),
           MAE = MAE(predictions, test.data$Fertility))

                                        # repeated k-fold cross validation

                         number = 5, repeats = 10)
model.2 <- train(Fertility ~ .,
                 data = swiss,
                 method = "lm",
                 trControl = t.control)
predictions_2 <- model %>% predict(swiss)
data.frame(R2 = R2(predictions_2, swiss$Fertility),
           RMSE = RMSE(predictions_2, swiss$Fertility),
           MAE = MAE(predictions_2, swiss$Fertility))
#+END_SRC
*** Confusion matrix
- The confusion matrix can be used to compute various summaries for
  classification models
- Rows correspond to what it was predicted
- Columns correspond to the known truth
- Sensitivity:
\begin{equation}
\frac{T.positives}{T.positives + F.negatives}
\end{equation}
 
- Specificity:
\begin{equation}
\frac{T.negatives}{T.negatives + F.positives}
\end{equation}

#+BEGIN_SRC R :results output
                                        # Load pkg
pkg <- c("tidyverse", "caret")
lapply(pkg, library, character.only = TRUE)

                                        # Using dummy data
x <- factor(ceiling(runif(1000)-0.20)) # predictions
y <- factor(ceiling(runif(1000)-0.25)) # references
table(x, y)

                                        # confusion matrix
confusionMatrix(x, y, positive = "1")
#+END_SRC
*** Decision tree
R code to generate a decision tree
- First a tree is generated
- Later on is pruned
- In this example the difference is not very notorious
#+BEGIN_SRC R :results output :session rs
library(rpart)
library(tree)
setwd("/home/nicoluarte/Downloads")
df = read.table('cleveland.txt', h=T)
head(df)
summary(df)

                                        # Using rpart

## no data standarization needed for trees

set.seed(123)

## creating the first tree

tree.1 = rpart(df[,14] ~ .,
               data=df[,1:13],
               cp=0.0001,parms=list(split="information"),
               method="class")

##split information means entropy/ split could be gini - cp is the complexity parameter.

par(xpd=TRUE)
plot(tree.1, uniform=T);
text(tree.1, all=T, pretty=T, fancy=T, use.n=T, fwidth=0.3, fheight=0.3)

##pretty is for compatibility with tree package. Considers the minimum length for abbreviation of character or factor variables (4 L).

## Pruning

plotcp(tree.1) ## Cross-validation results

printcp(tree.1)

tree.1$cptable[which.min(tree.1$cptable[,"xerror"]),"CP"]

tree.2<-prune(tree.1,cp=0.01102941)

par(xpd=TRUE)
plot(tree.2, uniform=T);
text(tree.2, all=T, pretty=T, fancy=T, use.n=T, fwidth=0.3, fheight=0.3)

plotcp(tree.2) ## Cross-validation results

printcp(tree.2)

#+END_SRC

#+RESULTS:
#+begin_example
  age gender     cp trestbps chol  fbs restecg thatach exang oldpeak slope ca
1  63   male angina      145  233 true     hyp     150   fal     2.3  down  0
2  67   male asympt      160  286  fal     hyp     108  true     1.5  flat  3
3  67   male asympt      120  229  fal     hyp     129  true     2.6  flat  2
4  37   male notang      130  250  fal    norm     187   fal     3.5  down  0
5  41    fem abnang      130  204  fal     hyp     172   fal     1.4    up  0
6  56   male abnang      120  236  fal    norm     178   fal     0.8    up  0
  thal diag Col15
1  fix buff     H
2 norm sick    S2
3  rev sick    S1
4 norm buff     H
5 norm buff     H
6 norm buff     H
      age         gender         cp         trestbps          chol      
 Min.   :29.00   fem : 95   abnang: 49   Min.   : 94.0   Min.   :126.0  
 1st Qu.:48.00   male:201   angina: 23   1st Qu.:120.0   1st Qu.:211.0  
 Median :56.00              asympt:141   Median :130.0   Median :242.5  
 Mean   :54.52              notang: 83   Mean   :131.6   Mean   :247.2  
 3rd Qu.:61.00                           3rd Qu.:140.0   3rd Qu.:275.2  
 Max.   :77.00                           Max.   :200.0   Max.   :564.0  
   fbs      restecg       thatach       exang        oldpeak       slope    
 fal :253   abn :  4   Min.   : 71.0   fal :199   Min.   :0.000   down: 21  
 true: 43   hyp :145   1st Qu.:133.0   true: 97   1st Qu.:0.000   flat:137  
            norm:147   Median :152.5              Median :0.800   up  :138  
                       Mean   :149.6              Mean   :1.059             
                       3rd Qu.:166.0              3rd Qu.:1.650             
                       Max.   :202.0              Max.   :6.200             
       ca           thal       diag     Col15   
 Min.   :0.0000   fix : 18   buff:160   H :160  
 1st Qu.:0.0000   norm:163   sick:136   S1: 53  
 Median :0.0000   rev :115              S2: 35  
 Mean   :0.6791                         S3: 35  
 3rd Qu.:1.0000                         S4: 13  
 Max.   :3.0000

Classification tree:
rpart(formula = df[, 14] ~ ., data = df[, 1:13], method = "class", 
    parms = list(split = "information"), cp = 1e-04)

Variables actually used in tree construction:
[1] age     ca      cp      exang   oldpeak thal    thatach

Root node error: 136/296 = 0.45946

n= 296 

         CP nsplit rel error  xerror     xstd
1 0.4926471      0   1.00000 1.00000 0.063044
2 0.0514706      1   0.50735 0.63971 0.057630
3 0.0404412      3   0.40441 0.52941 0.054276
4 0.0220588      5   0.32353 0.44853 0.051170
5 0.0110294      6   0.30147 0.44118 0.050857
6 0.0036765      8   0.27941 0.44118 0.050857
7 0.0001000     10   0.27206 0.46324 0.051780
[1] 0.01102941

Classification tree:
rpart(formula = df[, 14] ~ ., data = df[, 1:13], method = "class", 
    parms = list(split = "information"), cp = 1e-04)

Variables actually used in tree construction:
[1] age   ca    cp    exang thal 

Root node error: 136/296 = 0.45946

n= 296 

        CP nsplit rel error  xerror     xstd
1 0.492647      0   1.00000 1.00000 0.063044
2 0.051471      1   0.50735 0.63971 0.057630
3 0.040441      3   0.40441 0.52941 0.054276
4 0.022059      5   0.32353 0.44853 0.051170
5 0.011029      6   0.30147 0.44118 0.050857
6 0.011029      8   0.27941 0.44118 0.050857
#+end_example
** 11/07/2019, GLM
*** Linear regression
**** Conditions
**** Multiple linear regression
*** GLM
- A function is applied to the X's, or a transformation. These are
called link functions
- Started modelling probability of event (Bernoulli, logit of 'p')
- Logit predicts 'odds' <- logistic regression
- In GLM response variable can have any distribution
Using coimbra breast cancer dataset
*CHALLENGE REMOVE OUTLIERS AND RE-RUN ANALYSIS*
- There's not much difference in removing outliers
#+BEGIN_SRC R :results output
setwd("/home/nicoluarte/Downloads/")
df <- read.csv("dataR2.csv")
head(df)
resp <- c(df$Classification - 1)

                                        # compare cancer/no-cancer by age
library(doBy)
summaryBy(Age~resp, data = df, FUN = c(mean, median))

                                        # compare by glucose
summaryBy(Glucose~resp, data = df, FUN = c(mean, median))
summaryBy(Insulin~resp, data = df, FUN = c(mean, median))

                                        # t-test to check means
t.test(Age~resp, data = df)
t.test(Glucose~resp, data = df)
t.test(BMI~resp, data = df)
                                        # re-code variable
df$Glucose2 <- ifelse(df$Glucose<=100, "<=100", ">100")
chisq.test(table(df$Glucose2, resp))

                                        # OR calculation
or <- (44*27)/(8*37)

                                        # Plots
plot(resp~Glucose, data = df)
abline(lm(resp~Glucose, data = df), col = "red")

                                        # Logistic regression
mdl.0 = glm(resp~Glucose2, data = df, family = binomial(link = "logit"))
mdl.1 = glm(resp~Glucose, data = df, family = binomial(link = "logit"))

                                        # Calculating odds
exp(1.3897) # 4 times greater the chance to get cancer

                                        # Box plot
boxplot(Glucose~resp, data = df)

                                        # Logistic regression insulin2
df$Insulin2 <- ifelse(df$Insulin<=8, "<=8", ">8")
mdl.2 = glm(resp~Insulin2, data = df, family = binomial(link = "logit"))
summary(mdl.2)

mdl.3 <- glm(resp~Glucose, data = df, family = binomial(link = "logit"))
summary(mdl.3)

                                        # Calculating odds for different values
exp(0.07867*5)
plot(0.07867*1:10)

                                        # multi-variable model
mdl.4 <- glm(resp~Glucose + Insulin, data = df, family = binomial(link = "logit"))
summary(mdl.4)
plot(Glucose~Insulin, data = df)

                                        # Adding control variables
mdl.5 <- glm(resp~Age + BMI + Glucose, data = df, family = binomial(link = "logit"))
summary(mdl.5)
exp(mdl.5$coefficients["Glucose"]) # each glucose point has a 10%~ effect on chance of cancer

                                        # ROC curve
library(pROC)
prob <- predict(mdl.5, type = c("response"))
roc(resp~prob, data = df, plot = T)

                                        # Use all variables
full.mdl <- glm(resp~., data = df[,1:9], family = binomial(link = "logit"))
summary(full.mdl)

                                        # Prune!

new_vars = setdiff(names(df[,1:9]),c(names(full.mdl$coefficients)[which.max(full.mdl$coefficients)]))
prune.mdl <- glm(resp~., data = df[new_vars], family = binomial(link = "logit"))
summary(prune.mdl)

                                        # Calculate confusion matrix
library(caret)
preds <- as.numeric(predict(full.mdl, type = c("response")) > 0.5)
confusionMatrix(as.factor(preds), as.factor(resp))

                                        # Generate same model without outliers
df_removed_outliers = df[NA,] # same df but NA rows
df_removed_outliers["Classification"] <- df["Classification"]
df_removed_outliers$Classification <- df_removed_outliers$Classification - 1 # to get same levels
for (var in names(df[,1:9]))
{
  outliers <- boxplot.stats(df[,var]) # get the outlier of this variable
  df_target <- df[,var] # get the vector of values of this variable
  idx <- which(df_target %in% outliers$out) # get the idx of outliers in vector
  df_target[idx] <- NA # put NAN's in there
  df_removed_outliers[var] <- df_target # replace with filtered values
}

clean_df = na.omit(df_removed_outliers[,1:10])
full.mdl.filtered <- glm(resp~., data = clean_df[,1:9], # cleaning na rows
                         family = binomial(link = "logit"))
summary(full.mdl.filtered)

preds_filtered <- as.numeric(predict(full.mdl.filtered, type = c("response")) > 0.5)
confusionMatrix(as.factor(preds_filtered), as.factor(clean_df$Classification))
#+END_SRC

* PhD
** Doctorado en neurociencias UC
*** TODO postulacion
    DEADLINE: <2019-09-30 Mon> SCHEDULED: <2019-09-02 Mon>
    
*** Documentos
**** TODO Formulario de postulacion (segun formato en linea)
    SCHEDULED: <2019-08-19 Mon>
**** TODO Certificado de titulo o grado academico, original o copia legalizada ante notario
     SCHEDULED: <2019-08-05 Mon>
**** TODO Concentracion de notas de pregrado y otros estudios
     SCHEDULED: <2019-08-05 Mon>
Incluyendo estudios de perfeccionamiento y postgrado
**** TODO Dos cartas de recomendacion confidenciales (segun formato en linea)
     SCHEDULED: <2019-08-05 Mon>
Estas debe ser enviadas directamente por las personas que
recomiendan. Es deseable que las cartas provengan de personas con
grado academico de Doctor
**** TODO Carta de intencion
     SCHEDULED: <2019-07-10 Wed>
Presentar una declaracion de propositos, que incluya la formulacion de
un topico de interes relevante para su estudio durante el programa y
la dedicacion comprometidos para el programa. El postulante debe ser
tan especifico como sea posible en cuanto a sus intereses y objetivos
de investigacion a corto y largo plazo, en una extension no mas de
tres paginas a espacio y medio.
***** Declaración de propósitos
****** Motivación I
El cómo buscamos objetos, información, recompensas, alimentos, etc. Ha
sido lo que ha inspirado en mayor medida mi interés en la
neurociencia. A lo largo de mi vida he sentido profunda intriga en
cómo los humanos buscan en el espacio de posibilidades, para tomar una
decisión, para evocar una memoria en partícular o bien simplemente
para organizar cualquier compartamiento relativamente complejo, esto
es, sin tener de antemano consideradas todas las posibilidades y aún
pese a eso tener un buen desempeño en multiples tareas. Investigar
sobre los mecanismo subyacentes a ese fenómeno ha sido increíblemente
enriquecedor debido a la fuerte interdisciplinareidad que subyace al
campo. Esto me ha llevado a generar un profunda interés en seguir
desarrollando carrera en neurociencia, ya que, creo, el lograr
entender ese aparentemente simple mecainsmo de decisión en condiciones
de información incompleta, puede eventualmente, ser de gran utilidad
para la comprensión tanto de procesos de memoria y aprendizaje cómo de
ciertas patologías. Con la oportunidad del programa de Doctorado
espero contribuir a la investigación del aprendizaje y memoria.
****** Background
Cómo parte de mi formación en el programa de Magíster en Neurociencias
Social de la Universidad Diego Portales, investigue, cómo parte de un
artículo de revisión, las raíces evolutivas de la búsqueda semántica
(recuperación de memorias en tareas de evocación). Una de las
principales conclusiones fue que, aunque solo en grado tentativo,
parace existir un mecanismo compartido entre la búsqueda semántica y
el forrajeo ('foraging', el comportamiento de búsqueda de alimento),
teniendo este último patrones relativamente marcados que se extienden
a lo largo de miles de años, así cómo a través de multiples
especies. La posibilidad de que un mecanismo tan ubiquo, responsable
del comportamiento motil en la búsqueda de alimentos, pueda estar
relacionado por exaptación a un proceso fundamental de la memoria. Lo
que abre una posibilidad de establecer un mapeo evolutivo al menos a
este proceso de memoria.
****** Motivación II
Deseoso de aprender más sobre este posible vínculo entre forrajeo y
memoria, me adentre en las principales áreas aledañas de conocimiento,
tales como ecología, aprendizaje por reforzamiento ('reinforcement
learning') y modelos computacionales. Por la alta carga de modelos
estadísticos de las áreas mencionadas, me apunté para un programa de
diplomado en ciencia de datos de la Universidad Católica de
Chile. Además de este programa he realizado aprendizaje autonomo en
cursos en línea, con el fin de contar con todas las herramientas
técnicas que son demandadas para el área.
****** Motivación III (investigación) 
Adicional los programas mencionados anteriormente, desde julio del año
2018, me encuentro participando como investigador en un proyecto
FONDECYT conjunto entre la escuela de Arquitectura y Psicología de la
Univerdad Diego Portales. El tema central de esta investigación es el
estudio de la percepción de peatones en diferentes ámbientes
urbanos. Si bien, el tema no está relacionado directamente con el área
de interés, mi rol ha consistido en utilización de técnicas de visión
de máquina ('machine vision') y procesamiento de datos tanto para
'Eye-tracker' cómo para análisis de frecuencia de objetos. Lo
anterior, adicionado, a el aprendizaje de diversos lenguajes de
programación (MATLAB, Python, R, Bash) me ha permitido desarrollar
herramientas que son útiles en la investigación en general cómo
especificamente para el área de mi interés.
****** Formulación tópico de interés
******* Introducción
Mi tópico de interés reside en el estudio de la memoria,
especificamente la búsqueda semántica. Las memorias semánticas han
sido pensadas, teoricamente, cómo elementos pertenecientes a cierto
'espacio' que correlaciona con la similitud en significado (Lund
1996). Así se ha propuesto una 'distancia' entre los distintos
contenidos semánticos (Montez 2015), considerando aquello es esperable
que a lo largo de la evolución se hayan generado estrategias para
acceder, de manera útil e eficiente, a dichos contenidos. Las
estrategias de búsqueda para acceder a los contenidos semánticos han
sido relacionadas a aquellas del forrajeo (Hills 2015, 2008, 2006,
2009, Abbott 2015). Más aún, se ha propuesto que dichos contenidos se
agrupan en 'parches' (Abbot 2015), y que la búsqueda a través de ellos
puede ser descrita por caminatas aleatorias (Hills 2015), a la vez que
siguen comportamiento basados en reglas similares a los del forrajeo
(Davelaar 2015).

Dado que la búsqueda semántica es un comportamiento orientado a
objetivos, se puede conceptualizar cómo un comportamiento orientado a
la obtención de recompensas en un espacio de mútliples
posibilidades. Por lo anterior, puede ser estudiado desde el dilema de
exploración-explotación, dilema extensamente estudiado en la tarea
'n-armed bandit' (Macready 1998, Vermorel 2005). Ha sido propuesto que
los 'algoritmos' utilizados en el forrajeo, pueden proveer de
soluciones óptimas para dicho dilema (Viswanathan, Bartumeus 2005), lo
cuál aplicaria, igualmente, para estrategias en espacios semánticos
(Abbot 2015, Montez 2015). De esta manera se puede observar una
conexión entre un mecanismo evolutivamente antiguo (forrajeo) y el
proceso de acceso en la memoria. Lo cúal permitiria un enfoque
evolutivo comprensivo al estudio de la memoria.
******* Relevancia
El cómo se realiza la búsqueda en espacios semánticos es de
fundamental importacia, ya que es un espacio que está en activa
búsqueda durante la comprensión y producción de lenguaje, entre otras
(https://doi.org/10.1111/cogs.12249), por lo mismo el alcance de su
importancia para casi cualquier actividad cognitiva es de gran tamaño,
puediendo afectar de manera importante el comportamiento ante múltiples y
diferentes tareas.
****** Objetivos a corto plazo
Uno de los principales tópicos de discusión en el área de búsqueda
semántica es la organización y el tipo de la relaciones que conforman
el espacio semántico (Lund & Burgess 1996). Uno de los primeros
objetivos de investigación sería poder generar configuraciones
experimentales que permitiesen determinar, principalmente, (a) efecto
del contexto en las relaciones entre contenidos semánticos y (b) si el
tipo de búsqueda es más verosimil para contenidos encadenados de
manera asociativa o categorica.

Secundariamente, de manera experimental, ajustar modelos en tareas de
evocación de memoria, a modo de sugerir posibles mecanismos
generadores del comportamiento de búsqueda semántica. Los modelos mas
relevantes son (a) aquellos basados en reglas (Charnov 1976), (b)
modelos aleatorios simples (10.3389/fpsyg.2014.00086) y (c) modelos aleatorios
complejos (buscar cita, compound brownian walks) 

La metodología propuesta para el primer paso comprende,
principalmente, revisión de la literatura y estudios experimentales de
replica para el segundo paso. Las tareas especificas estarían
orientadas a evocación de memoria simple basada en categoría dentro de
franjas de tiempo.
****** Objetivos a largo plazo
******* Hipótesis sobre mecanismos subyacentes
******* Vinculación con mecanismos de búsqueda en espacios naturales

****** Compromiso
******* Disposición de investigación, demostrar comportamiento pasado
******* Disposición a aprendizaje autonomo detallando técnicas a aprender
**** TODO Fotocopia de la cedula de identidad o pasaporte
     SCHEDULED: <2019-07-10 Wed>
**** TODO Solicitud de ingreso a la universidad (segun formato)
     SCHEDULED: <2019-07-10 Wed>
** Doctorado en ingenieria de sistemas complejos
*** TODO postulacion
    SCHEDULED: <2019-09-01 Sun> DEADLINE: <2019-11-20 Wed>
*** Documentos
*SEND ALL BACKGROUND INFORMATION TO ANDREA PINTO AT EMAIL: postgrados.fic@uai.cl*
**** TODO Enter information at website [[https://ingenieria.uai.cl/phd/disc/admission/][application]]
     SCHEDULED: <2019-08-05 Mon>
**** TODO Résumé
     SCHEDULED: <2019-07-12 Fri>
**** TODO Photocopy of chilean ID
     SCHEDULED: <2019-07-10 Wed>
**** TODO Statement of interest
Format is open, to be determined by the applicant
**** TODO Letters of recommendation
     SCHEDULED: <2019-08-05 Mon>
At least two letters of recomendation from academic or direct
supervisors
**** TODO Certificates of degrees earned
     SCHEDULED: <2019-08-05 Mon>
**** TODO Grade point average
     SCHEDULED: <2019-08-05 Mon>
With ranking or relative position within the undergraduate and
graduate programs you have completed with their respective grade
scales
**** TODO English proficiency (TOEFL)
     SCHEDULED: <2019-08-05 Mon>
**** TODO Academic interview with the program director
** Doctorado en ciencias de la complejidad social (TBD)
[[https://dccs.udd.cl/es/][PHD PROGRAM]]
** Becas
   SCHEDULED: <2019-07-12 Fri>
*REVISAR*

* Projects
** FONDECYT
*** Initial inspection:
 #+BEGIN_SRC R :results output :session peatones
                                        # load packages
pkg <- c("dplyr", "ggplot2", "tidyverse", "corrplot", "Hmisc", "psycho")
lapply(pkg, library, character.only = TRUE)

                                        # load database
setwd("/home/nicoluarte/Downloads")
df <- data.frame(read.csv("data_fondecyt.csv"))
head(df)

                                        # inspect de data
cor <- na.omit(df) %>%
  correlation()
summary(cor)

                                        # logistic regression model
mdl.0 <- glm(Valence_num~Noise, data = df, family = binomial(link = "logit"))
summary(mdl.0)
t <- 0.5
mdl.0.pred <- as.numeric(predict(mdl.0, type = c("response")) > t)
caret::confusionMatrix(as.factor(mdl.0.pred), as.factor(df$Valence_num), positive = "1")

                                        # cross-validation
t.samples <- df$Valence_num %>%
  caret::createDataPartition(p = 0.8, list = FALSE)
t.data <- df[t.samples, ]
val.data <- df[-t.samples, ]

## re-build model with training data
mdl.1 <- glm(Valence_num~Noise, data = t.data, family = binomial(link = "logit"))
mdl.1.pred <- mdl.1 %>% predict(val.data, type = "response")

## ROC curve
pROC::roc(Valence_num~mdl.1.pred, data = val.data, plot = T)

caret::confusionMatrix(as.factor(as.numeric(mdl.1.pred > t)),
                       as.factor(val.data$Valence_num), positive = "1")

                                        # Repeated k-fold cross-validation
## fix pupil
df$Pupil <- as.numeric(as.character(df$Pupil))
t.control <- caret::trainControl(method = "repeatedcv",
                                 number = 5, repeats = 10)
mdl.2 <- caret::train(as.factor(Valence_num)~Noise+Pedestrians+Cars+Pupil+Neighbourhood_num+Socioeconomic_num,
                      data = na.omit(df),
                      method = "glm",
                      family = binomial(link = "logit"),
                      trControl = t.control,
                      preProcess=c("center", "scale"))
print(mdl.2)
 #+END_SRC

 #+RESULTS:
 #+begin_example

 Attaching package: ‘dplyr’

 The following objects are masked from ‘package:stats’:

     filter, lag

 The following objects are masked from ‘package:base’:

     intersect, setdiff, setequal, union

 ── [1mAttaching packages[22m ─────────────────────────────────────── tidyverse 1.2.1 ──
 [32m✔[39m [34mtibble [39m 2.1.3     [32m✔[39m [34mpurrr  [39m 0.3.2
 [32m✔[39m [34mtidyr  [39m 0.8.3     [32m✔[39m [34mstringr[39m 1.4.0
 [32m✔[39m [34mreadr  [39m 1.3.1     [32m✔[39m [34mforcats[39m 0.4.0
 ── [1mConflicts[22m ────────────────────────────────────────── tidyverse_conflicts() ──
 [31m✖[39m [34mdplyr[39m::[32mfilter()[39m masks [34mstats[39m::filter()
 [31m✖[39m [34mdplyr[39m::[32mlag()[39m    masks [34mstats[39m::lag()
 corrplot 0.84 loaded
 [[1]]
 [1] "dplyr"      "tikzDevice" "stats"      "graphics"   "grDevices" 
 [6] "utils"      "datasets"   "methods"    "base"      

 [[2]]
  [1] "ggplot2"    "dplyr"      "tikzDevice" "stats"      "graphics"  
  [6] "grDevices"  "utils"      "datasets"   "methods"    "base"      

 [[3]]
  [1] "forcats"    "stringr"    "purrr"      "readr"      "tidyr"     
  [6] "tibble"     "tidyverse"  "ggplot2"    "dplyr"      "tikzDevice"
 [11] "stats"      "graphics"   "grDevices"  "utils"      "datasets"  
 [16] "methods"    "base"      

 [[4]]
  [1] "corrplot"   "forcats"    "stringr"    "purrr"      "readr"     
  [6] "tidyr"      "tibble"     "tidyverse"  "ggplot2"    "dplyr"     
 [11] "tikzDevice" "stats"      "graphics"   "grDevices"  "utils"     
 [16] "datasets"   "methods"    "base"

   Subjects Valence_num  Valence       Noise Pedestrians      Cars       Pupil
 1        1           0 Negative 0.010767789  0.00000000 0.0000000         2.3
 2        1           0 Negative 0.012513303  0.46391753 0.1546392          []
 3        1           1 Positive 0.010372872  0.41237113 0.0000000  2.52325703
 4        1           1 Positive 0.009794006  0.09278351 0.0000000 2.079852955
 5        1           1 Positive 0.013058803  0.48453608 0.0000000 2.505264791
 6        1           1 Positive 0.024941132  0.16494845 0.0000000 2.590279936
   Neighbourhood_num Neighbourhood Socioeconomic_num Socioeconomic Sex_num
 1                 1          Cumm                 1        Middle       0
 2                 1          Cumm                 1        Middle       0
 3                 1          Cumm                 1        Middle       0
 4                 1          Cumm                 1        Middle       0
 5                 1          Cumm                 1        Middle       0
 6                 1          Cumm                 1        Middle       0

		       Subjects Valence_num      Noise  Pedestrians        Cars
 Subjects           1.000000000 -0.19441834  0.3631354  0.004621815  0.18556553
 Valence_num       -0.194418342  1.00000000 -0.1749219 -0.089847534 -0.04749806
 Noise              0.363135383 -0.17492187  1.0000000  0.133186803  0.10435992
 Pedestrians        0.004621815 -0.08984753  0.1331868  1.000000000 -0.06622748
 Cars               0.185565531 -0.04749806  0.1043599 -0.066227485  1.00000000
 Neighbourhood_num  0.986545524 -0.21435181  0.3646531 -0.009562540  0.18292625
 Socioeconomic_num  0.946027834 -0.18731924  0.3565664  0.011485792  0.12835608
 Sex_num            0.034478219  0.01316946  0.1426443  0.095992050  0.13677510
		   Neighbourhood_num Socioeconomic_num     Sex_num
 Subjects                 0.98654552        0.94602783  0.03447822
 Valence_num             -0.21435181       -0.18731924  0.01316946
 Noise                    0.36465314        0.35656638  0.14264431
 Pedestrians             -0.00956254        0.01148579  0.09599205
 Cars                     0.18292625        0.12835608  0.13677510
 Neighbourhood_num        1.00000000        0.95990857 -0.02666244
 Socioeconomic_num        0.95990857        1.00000000 -0.05920530
 Sex_num                 -0.02666244       -0.05920530  1.00000000
 #+end_example



 
