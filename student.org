* Data science program
#+STARTUP: latexpreview
** 09/07/2019, Cross validations, decision trees
*** Cross-validation
- Allows us to compare different machine learning methods and get a
sense of how well they will work in practice
- Typically this method split the data base into 75%~ for training and
25%~ for testing
- A similar principle is followed by 'leave one out cross validation',
where the model is trained in all but one sample, and that sample is
used to test model accuracy
- k-fold validation is the generalization, where data is divided in k
blocks
#+BEGIN_SRC R :results output 
              # Load pkg
  pkg <- c("tidyverse", "caret")
  lapply(pkg, library, character.only = TRUE)

              # load sample data
  data("swiss")

              # data-split
  set.seed(123)
  training.samples <- swiss$Fertility %>%
  createDataPartition(p = 0.8, list = FALSE) # 80/20 split
  train.data <- swiss[training.samples, ]
  test.data <- swiss[-training.samples, ]

              # build the model
  model <- lm(Fertility ~ ., data = train.data)

              # make predictions and compute acc
  predictions <- model %>% predict(test.data)
  data.frame(R2 = R2(predictions, test.data$Fertility),
    RMSE = RMSE(predictions, test.data$Fertility),
    MAE = MAE(predictions, test.data$Fertility))

              # repeated k-fold cross validation

        number = 5, repeats = 10)
  model.2 <- train(Fertility ~ .,
      data = swiss,
      method = "lm",
      trControl = t.control)
  predictions_2 <- model %>% predict(swiss)
  data.frame(R2 = R2(predictions_2, swiss$Fertility),
    RMSE = RMSE(predictions_2, swiss$Fertility),
    MAE = MAE(predictions_2, swiss$Fertility))
#+END_SRC
*** Confusion matrix
- The confusion matrix can be used to compute various summaries for
classification models
- Rows correspond to what it was predicted
- Columns correspond to the known truth
- Sensitivity:
\begin{equation}
\frac{T.positives}{T.positives + F.negatives}
\end{equation}

- Specificity:
\begin{equation}
\frac{T.negatives}{T.negatives + F.positives}
\end{equation}

#+BEGIN_SRC R :results output
				    # Load pkg
pkg <- c("tidyverse", "caret")
lapply(pkg, library, character.only = TRUE)

				    # Using dummy data
x <- factor(ceiling(runif(1000)-0.20)) # predictions
y <- factor(ceiling(runif(1000)-0.25)) # references
table(x, y)

                                        # confusion matrix
confusionMatrix(x, y, positive = "1")
#+END_SRC
*** Decision tree
R code to generate a decision tree
- First a tree is generated
- Later on is pruned
- In this example the difference is not very notorious
#+BEGIN_SRC R :results output :session rs
library(rpart)
library(tree)
setwd("/home/nicoluarte/Downloads")
df = read.table('cleveland.txt', h=T)
head(df)
summary(df)

                                        # Using rpart

## no data standarization needed for trees

set.seed(123)

## creating the first tree

tree.1 = rpart(df[,14] ~ .,
               data=df[,1:13],
               cp=0.0001,parms=list(split="information"),
               method="class")

##split information means entropy/ split could be gini - cp is the complexity parameter.

par(xpd=TRUE)
plot(tree.1, uniform=T);
text(tree.1, all=T, pretty=T, fancy=T, use.n=T, fwidth=0.3, fheight=0.3)

##pretty is for compatibility with tree package. Considers the minimum length for abbreviation of character or factor variables (4 L).

## Pruning

plotcp(tree.1) ## Cross-validation results

printcp(tree.1)

tree.1$cptable[which.min(tree.1$cptable[,"xerror"]),"CP"]

tree.2<-prune(tree.1,cp=0.01102941)

par(xpd=TRUE)
plot(tree.2, uniform=T);
text(tree.2, all=T, pretty=T, fancy=T, use.n=T, fwidth=0.3, fheight=0.3)

plotcp(tree.2) ## Cross-validation results

printcp(tree.2)

#+END_SRC

#+RESULTS:
#+begin_example
  age gender     cp trestbps chol  fbs restecg thatach exang oldpeak slope ca
1  63   male angina      145  233 true     hyp     150   fal     2.3  down  0
2  67   male asympt      160  286  fal     hyp     108  true     1.5  flat  3
3  67   male asympt      120  229  fal     hyp     129  true     2.6  flat  2
4  37   male notang      130  250  fal    norm     187   fal     3.5  down  0
5  41    fem abnang      130  204  fal     hyp     172   fal     1.4    up  0
6  56   male abnang      120  236  fal    norm     178   fal     0.8    up  0
  thal diag Col15
1  fix buff     H
2 norm sick    S2
3  rev sick    S1
4 norm buff     H
5 norm buff     H
6 norm buff     H
      age         gender         cp         trestbps          chol      
 Min.   :29.00   fem : 95   abnang: 49   Min.   : 94.0   Min.   :126.0  
 1st Qu.:48.00   male:201   angina: 23   1st Qu.:120.0   1st Qu.:211.0  
 Median :56.00              asympt:141   Median :130.0   Median :242.5  
 Mean   :54.52              notang: 83   Mean   :131.6   Mean   :247.2  
 3rd Qu.:61.00                           3rd Qu.:140.0   3rd Qu.:275.2  
 Max.   :77.00                           Max.   :200.0   Max.   :564.0  
   fbs      restecg       thatach       exang        oldpeak       slope    
 fal :253   abn :  4   Min.   : 71.0   fal :199   Min.   :0.000   down: 21  
 true: 43   hyp :145   1st Qu.:133.0   true: 97   1st Qu.:0.000   flat:137  
            norm:147   Median :152.5              Median :0.800   up  :138  
                       Mean   :149.6              Mean   :1.059             
                       3rd Qu.:166.0              3rd Qu.:1.650             
                       Max.   :202.0              Max.   :6.200             
       ca           thal       diag     Col15   
 Min.   :0.0000   fix : 18   buff:160   H :160  
 1st Qu.:0.0000   norm:163   sick:136   S1: 53  
 Median :0.0000   rev :115              S2: 35  
 Mean   :0.6791                         S3: 35  
 3rd Qu.:1.0000                         S4: 13  
 Max.   :3.0000

Classification tree:
rpart(formula = df[, 14] ~ ., data = df[, 1:13], method = "class", 
    parms = list(split = "information"), cp = 1e-04)

Variables actually used in tree construction:
[1] age     ca      cp      exang   oldpeak thal    thatach

Root node error: 136/296 = 0.45946

n= 296 

         CP nsplit rel error  xerror     xstd
1 0.4926471      0   1.00000 1.00000 0.063044
2 0.0514706      1   0.50735 0.63971 0.057630
3 0.0404412      3   0.40441 0.52941 0.054276
4 0.0220588      5   0.32353 0.44853 0.051170
5 0.0110294      6   0.30147 0.44118 0.050857
6 0.0036765      8   0.27941 0.44118 0.050857
7 0.0001000     10   0.27206 0.46324 0.051780
[1] 0.01102941

Classification tree:
rpart(formula = df[, 14] ~ ., data = df[, 1:13], method = "class", 
    parms = list(split = "information"), cp = 1e-04)

Variables actually used in tree construction:
[1] age   ca    cp    exang thal 

Root node error: 136/296 = 0.45946

n= 296 

        CP nsplit rel error  xerror     xstd
1 0.492647      0   1.00000 1.00000 0.063044
2 0.051471      1   0.50735 0.63971 0.057630
3 0.040441      3   0.40441 0.52941 0.054276
4 0.022059      5   0.32353 0.44853 0.051170
5 0.011029      6   0.30147 0.44118 0.050857
6 0.011029      8   0.27941 0.44118 0.050857
#+end_example
** 11/07/2019, GLM
*** Linear regression
**** Conditions
**** Multiple linear regression
*** GLM
- A function is applied to the X's, or a transformation. These are
called link functions
- Started modelling probability of event (Bernoulli, logit of 'p')
- Logit predicts 'odds' <- logistic regression
- In GLM response variable can have any distribution
Using coimbra breast cancer dataset
*CHALLENGE REMOVE OUTLIERS AND RE-RUN ANALYSIS*
- There's not much difference in removing outliers
#+BEGIN_SRC R :results output
setwd("/home/nicoluarte/Downloads/")
df <- read.csv("dataR2.csv")
head(df)
resp <- c(df$Classification - 1)

                                        # compare cancer/no-cancer by age
library(doBy)
summaryBy(Age~resp, data = df, FUN = c(mean, median))

                                        # compare by glucose
summaryBy(Glucose~resp, data = df, FUN = c(mean, median))
summaryBy(Insulin~resp, data = df, FUN = c(mean, median))

                                        # t-test to check means
t.test(Age~resp, data = df)
t.test(Glucose~resp, data = df)
t.test(BMI~resp, data = df)
                                        # re-code variable
df$Glucose2 <- ifelse(df$Glucose<=100, "<=100", ">100")
chisq.test(table(df$Glucose2, resp))

                                        # OR calculation
or <- (44*27)/(8*37)

                                        # Plots
plot(resp~Glucose, data = df)
abline(lm(resp~Glucose, data = df), col = "red")

                                        # Logistic regression
mdl.0 = glm(resp~Glucose2, data = df, family = binomial(link = "logit"))
mdl.1 = glm(resp~Glucose, data = df, family = binomial(link = "logit"))

                                        # Calculating odds
exp(1.3897) # 4 times greater the chance to get cancer

                                        # Box plot
boxplot(Glucose~resp, data = df)

                                        # Logistic regression insulin2
df$Insulin2 <- ifelse(df$Insulin<=8, "<=8", ">8")
mdl.2 = glm(resp~Insulin2, data = df, family = binomial(link = "logit"))
summary(mdl.2)

mdl.3 <- glm(resp~Glucose, data = df, family = binomial(link = "logit"))
summary(mdl.3)

                                        # Calculating odds for different values
exp(0.07867*5)
plot(0.07867*1:10)

                                        # multi-variable model
mdl.4 <- glm(resp~Glucose + Insulin, data = df, family = binomial(link = "logit"))
summary(mdl.4)
plot(Glucose~Insulin, data = df)

                                        # Adding control variables
mdl.5 <- glm(resp~Age + BMI + Glucose, data = df, family = binomial(link = "logit"))
summary(mdl.5)
exp(mdl.5$coefficients["Glucose"]) # each glucose point has a 10%~ effect on chance of cancer

                                        # ROC curve
library(pROC)
prob <- predict(mdl.5, type = c("response"))
roc(resp~prob, data = df, plot = T)

                                        # Use all variables
full.mdl <- glm(resp~., data = df[,1:9], family = binomial(link = "logit"))
summary(full.mdl)

                                        # Prune!

new_vars = setdiff(names(df[,1:9]),c(names(full.mdl$coefficients)[which.max(full.mdl$coefficients)]))
prune.mdl <- glm(resp~., data = df[new_vars], family = binomial(link = "logit"))
summary(prune.mdl)

                                        # Calculate confusion matrix
library(caret)
preds <- as.numeric(predict(full.mdl, type = c("response")) > 0.5)
confusionMatrix(as.factor(preds), as.factor(resp))

                                        # Generate same model without outliers
df_removed_outliers = df[NA,] # same df but NA rows
df_removed_outliers["Classification"] <- df["Classification"]
df_removed_outliers$Classification <- df_removed_outliers$Classification - 1 # to get same levels
for (var in names(df[,1:9]))
{
  outliers <- boxplot.stats(df[,var]) # get the outlier of this variable
  df_target <- df[,var] # get the vector of values of this variable
  idx <- which(df_target %in% outliers$out) # get the idx of outliers in vector
  df_target[idx] <- NA # put NAN's in there
  df_removed_outliers[var] <- df_target # replace with filtered values
}

clean_df = na.omit(df_removed_outliers[,1:10])
full.mdl.filtered <- glm(resp~., data = clean_df[,1:9], # cleaning na rows
                         family = binomial(link = "logit"))
summary(full.mdl.filtered)

preds_filtered <- as.numeric(predict(full.mdl.filtered, type = c("response")) > 0.5)
confusionMatrix(as.factor(preds_filtered), as.factor(clean_df$Classification))
#+END_SRC

* PhD
** Doctorado en neurociencias UC
*** TODO postulación
    DEADLINE: <2019-09-30 Mon> SCHEDULED: <2019-09-02 Mon>
    
*** Documentos
**** TODO Formulario de postulación (según formato en linea)
    SCHEDULED: <2019-07-16 Tue>
**** TODO Certificado de titulo o grado académico, original o copia legalizada ante notario
     SCHEDULED: <2019-07-16 Tue>
**** TODO Concentración de notas de pre-grado y otros estudios + ranking de egreso promoción
     SCHEDULED: <2019-07-16 Tue>
Incluyendo estudios de perfeccionamiento y postgrado
**** TODO Dos cartas de recomendación confidenciales (según formato en linea)
     SCHEDULED: <2019-07-22 Mon>
Estas debe ser enviadas directamente por las personas que
recomiendan. Es deseable que las cartas provengan de personas con
grado académico de Doctor
**** TODO Carta de intención
     SCHEDULED: <2019-07-17 Wed>
Presentar una declaración de propósitos, que incluya la formulación de
un tópico de interés relevante para su estudio durante el programa y
la dedicación comprometidos para el programa. El postulante debe ser
tan especifico como sea posible en cuanto a sus intereses y objetivos
de investigación a corto y largo plazo, en una extensión no mas de
tres paginas a espacio y medio.
***** Declaración de propósitos
#+AUTHOR: Luis Nicolás Luarte Rodríguez
#+OPTIONS: toc:nil date:nil
#+LATEX_HEADER: \usepackage{setspace}
#+LATEX_HEADER: \onehalfspacing
#+LATEX_HEADER: \usepackage[round]{natbib} 
****** Motivación personal para el programa de Doctorado
El cómo buscamos objetos, información, recompensas, alimentos, etc. Ha
sido lo que ha inspirado en mayor medida mi interés en la
neurociencia. A lo largo de mi vida he sentido profunda intriga en
cómo los humanos buscan en el espacio de posibilidades, para tomar una
decisión, para evocar una memoria en particular o bien simplemente
para organizar cualquier comportamiento relativamente complejo, esto
es, sin tener de antemano consideradas todas las posibilidades y aún
pese a eso tener un buen desempeño en múltiples tareas. Investigar
sobre los mecanismo subyacentes a ese fenómeno ha sido increíblemente
enriquecedor debido al fuerte componente interdisciplinar que subyace al
campo. Esto me ha llevado a generar un profunda interés en seguir
desarrollando carrera en neurociencia, ya que, creo, el lograr
entender ese aparentemente simple mecanismo de decisión en condiciones
de información incompleta, puede eventualmente, ser de gran utilidad
para la comprensión tanto de procesos de memoria y aprendizaje cómo de
ciertas patologías. Con la oportunidad del programa de Doctorado
espero contribuir a la investigación del aprendizaje y memoria.

Cómo parte de mi formación en el programa de Magíster en Neurociencias
Social de la Universidad Diego Portales, investigue, cómo parte de un
artículo de revisión, las raíces evolutivas de la búsqueda semántica
(recuperación de memorias en tareas de evocación). Una de las
principales conclusiones fue que, aunque solo en grado tentativo,
parece existir un mecanismo compartido entre la búsqueda semántica y
el forrajeo ('foraging', el comportamiento de búsqueda de alimento),
teniendo este último patrones relativamente marcados que se extienden
a lo largo de miles de años, así cómo a través de múltiples
especies. La posibilidad de que un mecanismo tan ubicuo, responsable
del comportamiento de desplazamiento en la búsqueda de alimentos, pueda estar
relacionado por exaptación a un proceso fundamental de la memoria. Lo
que abre una posibilidad de establecer un mapeo evolutivo al menos a
este proceso de memoria.

Deseoso de aprender más sobre este posible vínculo entre forrajeo y
memoria, me adentre en las principales áreas aledañas de conocimiento,
tales como ecología, aprendizaje por reforzamiento ('reinforcement
learning') y modelos computacionales. Por la alta carga de modelos
estadísticos de las áreas mencionadas, me apunté para un programa de
diplomado en ciencia de datos de la Universidad Católica de
Chile. Además de este programa he realizado aprendizaje autónomo en
cursos en línea, con el fin de contar con todas las herramientas
técnicas que son demandadas para el área.

Adicional los programas mencionados anteriormente, desde julio del año
2018, me encuentro participando como investigador en un proyecto
FONDECYT conjunto entre la escuela de Arquitectura y Psicología de la
Universidad Diego Portales. El tema central de esta investigación es el
estudio de la percepción de peatones en diferentes ambientes
urbanos. Si bien, el tema no está relacionado directamente con el área
de interés, mi rol ha consistido en utilización de técnicas de visión
de máquina ('machine vision') y procesamiento de datos tanto para
'Eye-tracker' cómo para análisis de frecuencia de objetos. Lo
anterior, adicionado a el aprendizaje de diversos lenguajes de
programación (MATLAB, Python, R, Bash), me ha permitido desarrollar
herramientas que son útiles en la investigación en general cómo
específicamente para el área de mi interés.

****** Formulación tópico de interés
Mi tópico de interés reside en el estudio de la memoria,
específicamente la búsqueda semántica. Las memorias semánticas han
sido pensadas, teóricamente, cómo elementos pertenecientes a cierto
'espacio' que correlaciona con la similitud en significado (Lund
1996). Así se ha propuesto una 'distancia' entre los distintos
contenidos semánticos (Montez 2015), considerando aquello es esperable
que a lo largo de la evolución se hayan generado estrategias para
acceder, de manera útil e eficiente, a dichos contenidos. Las
estrategias de búsqueda para acceder a los contenidos semánticos han
sido relacionadas a aquellas del forrajeo (Hills 2015, 2008, 2006,
2009, Abbott 2015). Más aún, se ha propuesto que dichos contenidos se
agrupan en 'parches' (Abbot 2015), y que la búsqueda a través de ellos
puede ser descrita por caminatas aleatorias (Hills 2015), a la vez que
siguen comportamiento basados en reglas similares a los del forrajeo
(Davelaar 2015)

Dado que la búsqueda semántica es un comportamiento orientado a
objetivos, se puede conceptualizar cómo un comportamiento orientado a
la obtención de recompensas en un espacio de múltiples
posibilidades. Por lo anterior, puede ser estudiado desde el dilema de
exploración-explotación, dilema extensamente estudiado en la tarea
'n-armed bandit' (Macready 1998, Vermorel 2005). Ha sido propuesto que
los 'algoritmos' utilizados en el forrajeo, pueden proveer de
soluciones óptimas para dicho dilema (Viswanathan, Bartumeus 2005), lo
cuál aplicaria, igualmente, para estrategias en espacios semánticos
(Abbot 2015, Montez 2015). De esta manera se puede observar una
conexión entre un mecanismo evolutivamente antiguo (forrajeo) y el
proceso de acceso en la memoria. Lo cúal permitiria un enfoque
evolutivo comprensivo al estudio de la memoria.

El cómo se realiza la búsqueda en espacios semánticos es de
fundamental importancia, ya que es un espacio que está en activa
búsqueda durante la comprensión y producción de lenguaje, entre otras
(https://doi.org/10.1111/cogs.12249), por lo mismo el alcance de su
importancia para casi cualquier actividad cognitiva es de gran tamaño,
pudiendo afectar de manera importante el comportamiento ante múltiples y
diferentes tareas.

****** Objetivos a corto plazo
Uno de los principales tópicos de discusión en el área de búsqueda
semántica es la organización y el tipo de la relaciones que conforman
el espacio semántico (Lund & Burgess 1996). Uno de los primeros
objetivos de investigación sería poder generar configuraciones
experimentales que permitiesen determinar, principalmente, (a) efecto
del contexto en las relaciones entre contenidos semánticos
citep:schillerMemorySpaceUnderstanding2015 y (b) si el tipo de búsqueda es más
verosímil para contenidos encadenados de manera asociativa o categórica
citep:hillsOptimalForagingSemantic2012. 

Cómo segundo objetivo a corto plazo, de manera experimental, ajustar modelos en
tareas de evocación de memoria, a modo de sugerir posibles mecanismos
generadores del comportamiento de búsqueda semántica. Los modelos mas
relevantes son (a) aquellos basados en reglas citep:charnovOptimalForagingMarginal1976, (b)
modelos aleatorios simples citep:thompsonWalkingWikipediaScalefree2014 y (c) modelos aleatorios
complejos cómo discutido en citep:benhamouHowManyAnimals2007  
****** Objetivos a largo plazo
Los objetivos a corto plazo están relacionados, principalmente, con estudio de
comportamiento e inferencia de posibles mecanismos generadores. Por otra parte,
los objetivos a largo plazo buscarían conectar dichos modelos a sus estructuras
cerebrales (u otras) subyacentes. Uno de los candidatos parece ser el 'Locus
coeruleus' citep:kaneIncreasedLocusCoeruleus2017, corteza medial pre-frontal
ventromedial citep:kollingNeuralMechanismsForaging2012, corteza cingulada
anterior citep:shenhavAnteriorCingulateEngagement2014, entre otras. Si bien la
función del 'Locus coeruleus' es extendida en el sistema de arousal, se observa
evidencia de participación significativa en comportamiento de
exploración-explotación relacionados al forrajeo
citep:aston-jonesAdaptiveGainRole2005, además la relativa facilidad en medición,
en conjunto con otras técnicas como electro-encefalograma, ha permitido
encontrar relación entre este y el forrajeo en situaciones experimentales
citep:slanziCombiningEyeTracking2017.

Finalmente, cómo objetivo a mayor largo plazo, y sólo a nivel exploratorio,
vincular las estructuras subyacentes a búsqueda semántica y forrajeo con sus
raíces evolutivas. De esta manera generalizando la función de dichas estructuras
al comportamiento orientado a objetivos citep:hillsAnimalForagingEvolution2006 
****** Compromiso de dedicación al programa de Doctorado
******* Disposición de investigación, demostrar comportamiento pasado
******* Disposición a aprendizaje autonomo detallando técnicas a aprender
bibliographystyle:apalike
bibliography:ref.bib
**** TODO CV
     SCHEDULED: <2019-07-17 Wed>
**** TODO Fotocopia de la cédula de identidad o pasaporte
     SCHEDULED: <2019-07-16 Tue>
**** TODO Solicitud de ingreso a la universidad (según formato)
     SCHEDULED: <2019-07-16 Tue>
** Doctorado en ingeniería de sistemas complejos
*** TODO postulacion
    SCHEDULED: <2019-09-01 Sun> DEADLINE: <2019-11-20 Wed>
*** Documentos
*SEND ALL BACKGROUND INFORMATION TO ANDREA PINTO AT EMAIL: postgrados.fic@uai.cl*
**** TODO Enter information at website [[https://ingenieria.uai.cl/phd/disc/admission/][application]]
     SCHEDULED: <2019-08-05 Mon>
**** TODO Résumé
     SCHEDULED: <2019-07-12 Fri>
**** TODO Photocopy of chilean ID
     SCHEDULED: <2019-07-10 Wed>
**** TODO Statement of interest
Format is open, to be determined by the applicant
**** TODO Letters of recommendation
     SCHEDULED: <2019-08-05 Mon>
At least two letters of recomendation from academic or direct
supervisors
**** TODO Certificates of degrees earned
     SCHEDULED: <2019-08-05 Mon>
**** TODO Grade point average
     SCHEDULED: <2019-08-05 Mon>
With ranking or relative position within the undergraduate and
graduate programs you have completed with their respective grade
scales
**** TODO English proficiency (TOEFL)
     SCHEDULED: <2019-08-05 Mon>
**** TODO Academic interview with the program director
** Doctorado en ciencias de la complejidad social (TBD)
[[https://dccs.udd.cl/es/][PHD PROGRAM]]
** Becas
   SCHEDULED: <2019-07-19 Fri>
Leer e imprimir el manual de becas chile, ver en profundidad bases para la
postulación de becas UC y UAI
** Correos
Diego Cosmelli: dcosmelli@uc.cl

Estimado profesor Diego Cosmelli,

Actualmente soy estudiante del programa de Magíster en Neurociencia Social de la
Universidad Diego Portales. Me encuentro en proceso de finalización del
Magíster, y he encontrado gran interés en el programa de Doctorado en
Neurociencias de su Universidad. 

Cómo parte de mi investigación de literatura tuve la oportunidad de leer su
artículo 'Modeling Search Behaviors during the Acquisition of Expertise in a
Sequential Decision-Making Task'. Específicamente el modelamiento de toma de
decisiones secuenciales me provocó gran interés, ya que el tema principal de mi
proyecto de tesis se centra en la raíces evolutivas de la toma de decisiones
secuenciales y los mecanismos neuronales subyacentes. He estado en búsqueda de
programas de Doctorado dónde pueda continuar el trabajo de investigación en esta
área. Mi proyecto (tentativo) se centra en el modelamiento de toma de decisiones
secuenciales tanto a nivel de comportamiento de desplazamiento en la búsqueda
(foraging) cómo a nivel de búsqueda semántica en espacios cognitivos.
Adicionalmente, recae mi interés en la formación de conciencia a través de los
procesos mencionados anteriormente en el espíritu de 'From foraging to
autonoetic consciousness: The primal self as a consequence of embodied
prospective foraging'.

Esperando no causar mayor molestia, quisiera saber si existe la posibilidad de
saber, si actualmente, está recibiendo estudiantes en calidad de
tutor/supervisor para el programa de Doctorado. Si es así, ¿estaría dispuesto a
seguir esta conversación por el medio que más guste?, sea por correo, teléfono o
una visita al campus/oficina. He investigado el sitio del programa en detalle, y
creo existe buen ajuste con mi intereses de investigación, principalmente por el
fuerte foco interdisciplinar (inherente al objeto de estudio de mi interés) y
por la posibilidad de expandir un línea de investigación relativamente novedosa.

Apreciando cualquier tiempo que me pudiese destinar, lo agradezco de antemano y
quedo atento a su respuesta.

Saludos cordiales,

Nicolás Luarte

* Projects
** FONDECYT
*** Initial inspection:
 #+BEGIN_SRC R :results output :session peatones
                                        # load packages
pkg <- c("dplyr", "ggplot2", "tidyverse", "corrplot", "Hmisc", "psycho")
invisible(lapply(pkg, library, character.only = TRUE))

                                        # load database
setwd("/home/nicoluarte/Downloads")
df <- data.frame(read.csv("data_fondecyt.csv"))
head(df)

                                        # inspect de data
cor <- na.omit(df) %>%
  correlation()
summary(cor)

                                        # logistic regression model
mdl.0 <- glm(Valence_num~Noise, data = df, family = binomial(link = "logit"))
summary(mdl.0)
t <- 0.5
mdl.0.pred <- as.numeric(predict(mdl.0, type = c("response")) > t)
caret::confusionMatrix(as.factor(mdl.0.pred), as.factor(df$Valence_num), positive = "1")

                                        # cross-validation
t.samples <- df$Valence_num %>%
  caret::createDataPartition(p = 0.8, list = FALSE)
t.data <- df[t.samples, ]
val.data <- df[-t.samples, ]

## re-build model with training data
mdl.1 <- glm(Valence_num~Noise, data = t.data, family = binomial(link = "logit"))
mdl.1.pred <- mdl.1 %>% predict(val.data, type = "response")

## ROC curve
roc.curve <- pROC::roc(Valence_num~mdl.1.pred, data = val.data, plot = T)

caret::confusionMatrix(as.factor(as.numeric(mdl.1.pred > t)),
                       as.factor(val.data$Valence_num), positive = "1")

                                        # Repeated k-fold cross-validation
## fix pupil
df$Pupil <- as.numeric(as.character(df$Pupil))
t.control <- caret::trainControl(method = "repeatedcv",
                                 number = 5, repeats = 10)
mdl.2 <- caret::train(as.factor(Valence_num)~Noise+Pedestrians+Cars+Neighbourhood_num,
                      data = na.omit(df),
                      method = "glm",
                      family = binomial(link = "logit"),
                      trControl = t.control,
                      preProcess=c("center", "scale"))
print(mdl.2)
mdl.2.pred <- mdl.2 %>% predict(val.data, type = "prob")

                                        # testing different 't' simple model
default <- caret::confusionMatrix(as.factor(as.numeric(mdl.1.pred > 0.5)),
                                  as.factor(val.data$Valence_num), positive = "1")
opt_t <- pROC::coords(roc.curve, "best")
optimal <- caret::confusionMatrix(as.factor(as.numeric(mdl.1.pred > opt_t["threshold"])),
                                  as.factor(val.data$Valence_num), positive = "1")
data.frame(default = c(default$byClass["Sensitivity"], default$byClass["Specificity"]),
           optimal = c(optimal$byClass["Sensitivity"], optimal$byClass["Specificity"]))

                                        # testing different 't' complete model
default.1 <- caret::confusionMatrix(as.factor(as.numeric(mdl.2.pred["1"] > 0.5)),
                                  as.factor(val.data$Valence_num), positive = "1")
roc.curve.1 <- pROC::roc(Valence_num~unlist(mdl.2.pred["1"]), data = val.data, plot = T)
opt_t.1 <- pROC::coords(roc.curve.1, "best")
optimal.1 <- caret::confusionMatrix(as.factor(as.numeric(unlist(mdl.2.pred["1"]) > opt_t.1["threshold"])),
                                  as.factor(val.data$Valence_num), positive = "1")
data.frame(default = c(default.1$byClass["Sensitivity"], default.1$byClass["Specificity"]),
           optimal = c(optimal.1$byClass["Sensitivity"], optimal.1$byClass["Specificity"]))
 #+END_SRC

 #+RESULTS:
 #+begin_example

   Subjects Valence_num  Valence       Noise Pedestrians      Cars       Pupil
 1        1           0 Negative 0.010767789  0.00000000 0.0000000         2.3
 2        1           0 Negative 0.012513303  0.46391753 0.1546392          []
 3        1           1 Positive 0.010372872  0.41237113 0.0000000  2.52325703
 4        1           1 Positive 0.009794006  0.09278351 0.0000000 2.079852955
 5        1           1 Positive 0.013058803  0.48453608 0.0000000 2.505264791
 6        1           1 Positive 0.024941132  0.16494845 0.0000000 2.590279936
   Neighbourhood_num Neighbourhood Socioeconomic_num Socioeconomic Sex_num
 1                 1          Cumm                 1        Middle       0
 2                 1          Cumm                 1        Middle       0
 3                 1          Cumm                 1        Middle       0
 4                 1          Cumm                 1        Middle       0
 5                 1          Cumm                 1        Middle       0
 6                 1          Cumm                 1        Middle       0

                   Subjects Valence_num   Noise Pedestrians    Cars
 Subjects                                                          
 Valence_num       -0.19***                                        
 Noise              0.36***    -0.17***                            
 Pedestrians             0       -0.09  0.13**                     
 Cars               0.19***      -0.05    0.1*       -0.07         
 Neighbourhood_num  0.99***    -0.21*** 0.36***      -0.01  0.18***
 Socioeconomic_num  0.95***    -0.19*** 0.36***       0.01  0.13** 
 Sex_num              0.03        0.01  0.14**         0.1  0.14** 
                   Neighbourhood_num Socioeconomic_num
 Subjects                                             
 Valence_num                                          
 Noise                                                
 Pedestrians                                          
 Cars                                                 
 Neighbourhood_num                                    
 Socioeconomic_num           0.96***                  
 Sex_num                      -0.03             -0.06

 Call:
 glm(formula = Valence_num ~ Noise, family = binomial(link = "logit"), 
     data = df)

 Deviance Residuals: 
     Min       1Q   Median       3Q      Max  
 -1.2618  -1.0714  -0.8653   1.2181   2.0739  

 Coefficients:
             Estimate Std. Error z value Pr(>|z|)    
 (Intercept)   0.2316     0.1372   1.689   0.0912 .  
 Noise       -26.2153     5.5992  -4.682 2.84e-06 ***
 ---
 Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

 (Dispersion parameter for binomial family taken to be 1)

     Null deviance: 1025.4  on 753  degrees of freedom
 Residual deviance: 1000.9  on 752  degrees of freedom
 AIC: 1004.9

 Number of Fisher Scoring iterations: 4

 Confusion Matrix and Statistics

           Reference
 Prediction   0   1
          0 391 244
          1  47  72

                Accuracy : 0.6141         
                  95% CI : (0.5783, 0.649)
     No Information Rate : 0.5809         
     P-Value [Acc
 NIR] : 0.03489        

                   Kappa : 0.132          

  Mcnemar's Test P-Value : < 2e-16        

             Sensitivity : 0.22785        
             Specificity : 0.89269        
          Pos Pred Value : 0.60504        
          Neg Pred Value : 0.61575        
              Prevalence : 0.41910        
          Detection Rate : 0.09549        
    Detection Prevalence : 0.15782        
       Balanced Accuracy : 0.56027        

        'Positive' Class : 1

 Setting levels: control = 0, case = 1
 Setting direction: controls < cases

 Confusion Matrix and Statistics

           Reference
 Prediction  0  1
          0 75 42
          1 17 16

                Accuracy : 0.6067          
                  95% CI : (0.5237, 0.6853)
     No Information Rate : 0.6133          
     P-Value [Acc
 NIR] : 0.601529        

                   Kappa : 0.099           

  Mcnemar's Test P-Value : 0.001781        

             Sensitivity : 0.2759          
             Specificity : 0.8152          
          Pos Pred Value : 0.4848          
          Neg Pred Value : 0.6410          
              Prevalence : 0.3867          
          Detection Rate : 0.1067          
    Detection Prevalence : 0.2200          
       Balanced Accuracy : 0.5455          

        'Positive' Class : 1

 Warning message:
 NAs introduced by coercion

 Generalized Linear Model 

 490 samples
   4 predictor
   2 classes: '0', '1' 

 Pre-processing: centered (4), scaled (4) 
 Resampling: Cross-Validated (5 fold, repeated 10 times) 
 Summary of sample sizes: 392, 392, 393, 391, 392, 392, ... 
 Resampling results:

   Accuracy   Kappa    
   0.5879787  0.1654871

 Warning message:
 In coords.roc(roc.curve, "best") :
   An upcoming version of pROC will set the 'transpose' argument to FALSE by default. Set transpose = TRUE explicitly to keep the current behavior, or transpose = FALSE to adopt the new one and silence this warning. Type help(coords_transpose) for additional information.

               default   optimal
 Sensitivity 0.2758621 0.7586207
 Specificity 0.8152174 0.5000000

 Setting levels: control = 0, case = 1
 Setting direction: controls < cases

 Warning message:
 In coords.roc(roc.curve.1, "best") :
   An upcoming version of pROC will set the 'transpose' argument to FALSE by default. Set transpose = TRUE explicitly to keep the current behavior, or transpose = FALSE to adopt the new one and silence this warning. Type help(coords_transpose) for additional information.

               default   optimal
 Sensitivity 0.4655172 0.8103448
 Specificity 0.7065217 0.4673913
 #+end_example



 
 

#  LocalWords:  correlaciona
* Defensa de Tesis
  SCHEDULED: <2019-07-21 Sun>
Comenzar con la preparación de la presentación y revisión de artículos novedosos
